Abstract
시각적 장소 인식에서 다양한 환경 조건과 관점에서 위치의 이미지를 정확하게 식별하고 일치시키는 것은 여전히 중요한 과제이다.
BoQ라는 새로운 기술을 소개하는데, 보편적인 장소별 속성을 캡처하도록 설계된 일련의 전역 쿼리를 학습한다.
셀프 어텐션을 사용하고 입력에서 직접 쿼리를 생성하는 기존 기술과 달리, BoQ는 교차 어텐션을 통해 입력 기능을 프로브하는 고유한 학습 가능한 글로벌 쿼리를 사용하여 일관된 정보 집계를 보장한다. 
또한 이 기술은 해석 가능한 어텐션 메커니즘을 제공하고 cnn 및 vision transformer 백본과 통합한다.
BoQ는 글로벌 검색 기술임에도 불구하고 Patch-netVLAD, TransVPR< R2Former와 같은 2단계 검색 방법을 능가하는 동시에 훨씬 더 빠르고 효율적이다.

1. Introduction
VPR은 시각적 기능을 이전에 방문한 장소의 데이터베이스와 비교하여 주어진 이미지에 묘사된 장소의 지리적 위치를 결정하는 것으로 구성된다.
역동적이고 끊임없이 변화하는 실제 환경의 특성은 VPR에 심각한 문제를 제기한다. 
이러한 문제는 VPR시스템의 운영 제약으로 인해 악화되며, VPR 시스템은 종종 제한된 메모리에서 실시간으로 작동해야 한다.
VPR 관련 신경망이 제안되었으며, CNN을 활용하여 고수준 특징을 추출한 다음 이러한 특징을 단일 전역 설명자로 통합하는 집계 계층이 뒤를 따랐다.

최근 vit는 이미지 분류, 물체 감지 및 의미론적 분할을 포함한 다양한 컴퓨터 비전 작업에서 놀라운 성능을 보여주었다.
그들의 성공은 이미지의 먼 부분 사이의 전체적인 종속성을 포착하는 셀프 어텐션 메커니즘에 기인할 수 있다.
그러나 현재의 트랜스포머 기반 VPR 기술은 글로벌 디스크립터 검색을 통해 식별된 초기 후보 위치 세트를 구체화하기 위한 후처리 단계인 re-ranking에 의존하는 경우가 많다.
순위 재지정 프로세스는 계산 및 메모리 집약적이다. 
중요한 것은 순위 재지정을 사용하지 않는 단일 스테이지 검색 방법인 BoQ가 2단계 검색 방법보다 성능이 뛰어나면서도 컴퓨팅 및 메모리 리소스 측면에서 훨씬 더 효율적이라는 것이다.

2. Related Work
초기의 VPR 기술은 SIFT< SURF 및 ORB와 같은 수작업으로 제작된 로컬 기능에 의존했으며, 이는 BoW 또는 VLAD와 같은 기술을 사용하여 전역 설명자로 집계되었다.
BoW는 시각적 어휘를 학습하는 것과 관련이 있으며, 각 시각적 단어는 특정 시각적 특성을 나타낸다.

Transformer-based VPR
트랜스포머 아키텍처는 처음에 자연어 처리를 위해 도입되었으며, 나중에 컴퓨터 비전 애플리케이션용 비전 트랜스포머에 적용되었다.
상위 후보를 식별하기 위해 전역 설명자를 사용하는 전역 검색으로 시작한 다음, 로컬 기능을 기반으로 결과를 구체화하는 계산 집약적인 순위 재지점 단계가 이어진다.
cnn을 사용하고 어텐션 융합을 위해 트랜스포머를 사용하여 전역 이미지 설명자를 생성하고 기하학적 검증을 위한 추가 패치 수준 설명자를 만드는 transvpr을 도입했다.

3. Methodology
시각적 장소 인식에서는 지역 특징의 효과적인 집계가 정확하고 빠른 전역 검색에 매우 중요하다.
이 문제를 해결하기 위해 그림과 같이 엔드 투 엔드 훈련이 가능하고 놀라울 정도로 간단한 새로운 집계 아키텍처인 BoQ 기술을 제안하낟.
이 기술은 MHA 메커니즘에 의존하며, 이는 쿼리, 키, 값의 세 가지 입력을 취하고 이를 여러 병렬 헤드로 선형으로 투영한다.

이 메커니즘에서 쿼리는 중요한 역할을 한다. 
이들은 필터 집합으로 작동하여 입력의 어느 부분이 가장 관련성이 높은지 결정한다.
쿼리와 키 사이의 내적에서 파생된 어텐션 스코어는 기본적으로 입력의 각 부분에 제공해야 하는 어텐션 정도를 모델에 나타낸다.
반면, cross-attention은 쿼리가 키 및 값과 다른 원본에서 오는 시나리오이다.

R{3xHxW} 입력 이미지가 주어지면 먼저 백본 네트워크 또는 vit를 통해 처리하여 높은 수준의 기능을 추출한다.
cnn 백본의 경우 3x3 컨볼루션을 적용하여 차원을 줄이는 반면, vit 백본의 경우 동일한 목적으로 선형 투영을 적용한다.
결과를 차원 d의 N 로컬 피처의 시퀀스로 간주한다. 
그런 다음 transformer-encoder 장치와 BoQ 블록을 통해 X{0}를 처리한다. 각 인코더는 입력 기능을 변환하고 그 결과를 다음과 같이 후속 BoQ블록에 전달한다.
Xi = Encoderi(Xi−1)
여기서 X{i-1}은 i번째 인코더 유닛에 대한 기능 입력을 나타내고, Xi는 파이프라인의 다음 블록에 대한 입력이 되는 변환된 출력을 나타낸다.
각 BoQ 블록에는 Qi로 표시되는 M개의 학습 가능한 쿼리로 구성된 고정 세트가 포함되어 있다.
Q{i}를 사용하여 i번째 BoQ 블록의 정보를 집계하기 전에 먼저 그들 사이에 셀프 어텐션을 적용한다.
셀프 어텐션을 통해 학습 가능한 쿼리는 학습 단계에서 공유 정보를 통합할 수 있다.
다음으로, Q{i}와 현재 BoQ 블록의 입력 특징 Xi 사이에 cross-attention을 적용한다.

이를 통해 학습 가능한 쿼리는 Q{i}와 X{i} 사이의 상대 점수를 계산하여 각 입력 기능의 중요성을 동적으로 평가하고 이를 출력 Oi로 집계할 수 있다.
이렇게 하면 최종 설명자 O가 네트워크의 서로 다른 수준에서 집계된 정보를 결합하여 풍부하고 계층적인 표현을 형성한다.

Relations to other methods
BoQ


